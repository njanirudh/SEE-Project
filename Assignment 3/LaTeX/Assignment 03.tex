\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{array}
\usepackage{float}
\usepackage{pdfpages}

\usepackage[raggedright]{titlesec}
\usepackage[tmargin=3cm,bmargin=2.5cm,lmargin=1.1cm,rmargin=1.5cm]{geometry}
\hypersetup{
	colorlinks=true,
	linkcolor=black,
	filecolor=magenta,
	urlcolor=cyan,
}
\usepackage{sectsty}

\sectionfont{\LARGE}
\subsectionfont{\Large}
\subsubsectionfont{\Large}
\paragraphfont{\large}


\setcounter{secnumdepth}{5}

\newcolumntype{C}[1]{%
	>{\vbox to 2.5ex\bgroup\vfill\centering\arraybackslash}%
	p{#1}%
	<{\vskip-\baselineskip\vfill\egroup}}  

\author{\vspace{0.4cm}
	\Large{Anirudh N J}\\\vspace{0.4cm}
	\Large{Somesh Devagekar} \\\vspace{0.8cm}
	\Large{Raina Thomas}}

\title{
	\vspace*{5cm}
	\textbf{\Large{Scientific Experimentation and Evaluation}}
	}
	
\date{May 01, 2019}			
\begin{document}

\begin{titlepage}

	\maketitle
	
\end{titlepage}

	\Large
	\tableofcontents
	\newpage



\section{Task 1 : Manual Motion Observation}

\subsection{Aim}
\Large
The aim of this project is to construct a LEGO NXT differential drive robot and measure the observable end pose variation for three different trajectories: an arc to the left, driving straight and an arc to the right.
\vspace{0.5cm}

The experiment of measuring the end pose was done by measuring the pose using aruco markers and Computer Vision.
   

\subsubsection{Experimental Setup}
	
	\subsubsection{Software Setup}
		\vspace{0.3cm}
	\textbf{Software Installation}\\
			
		The following softwares were installed in the PC for driving the robot :
			\vspace{0.3cm}
			\begin{enumerate}
				
				\item
				Java SE Development Kit 8 was installed in the Windows Operating System of the PC. The software was downloaded from the website :\\ \href{https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html}{https://www.oracle.com}
				\vspace{0.2cm}
				
				\item
				Eclipse IDE for Java Developers was downloaded and installed from the website 
				\href{http://eclipse.bluemix.net/packages/neon/?JAVA-WIN32}{http://eclipse.bluemix.net}. This IDE is the platform used for developing the program for driving the robot.
				\vspace{0.2cm}
				
				\item
				The leJOS NXT Fantom Driver was downloaded from  \href{https://www.lego.com/en-us/mindstorms/downloads}{https://www.lego.com/en-us/mindstorms/download}. 
				\vspace{0.2cm}
				
				\item
				The leJOS NXJ software was downloaded from \href{https://sourceforge.net/projects/nxt.lejos.p/files/}{https://sourceforge.net} and installed in the PC using the Windows Installer.
				\vspace{0.2cm}
				
				\item
				The leJOS NXJ plug-in was added to Eclipse.
				\vspace{0.5cm}
								
			\end{enumerate}
			\vspace{0.3cm}
			\textbf{Programming the robot}
	
			\begin{enumerate}
				\item
				The Lego NXT Java template code provided in the website below was modified for use in the robot.
				\href{https://lea.hochschule-bonn-rhein-sieg.de/ilias.php?ref_id=571436&cmd=view&cmdClass=ilrepositorygui&cmdNode=t3&baseClass=ilrepositorygui}{https://lea.hochschule-bonn-rhein-sieg.de}
				\item
				A LeJOS NXT Project was created in Eclipse and the template code was added to the project and certain parameters in the code was modified. The parameters that were modified for our experimental setup are given in the table below.				
					
				\begin{table}[ht]				
					\centering
				\begin{tabular}{ | C{3cm} | C{3cm}|  C{7cm} |} 
					\hline
					\textbf{Parameter} & \textbf{Value} & \textbf{Reason}\\ 
					\hline
					SLEEP\_TIME   & 3000.0 &  Increased to make the robot drive for a longer duration\\ 
					\hline
					TURN\_RATE  & 10.0 & Decreased to prevent the robot from making sharp turns\\ 
					\hline
				\end{tabular}
					\caption{Modified Code Parameters}
				  	\label{Tab:Tcr}
				\end{table}
		\item
		The NXT Device was connected to the PC via a USB Cable. The NXJ firmware was flashed into the device. The modified code was compiled and run as an LeJOS NXT Program to create a .nxj file. This was automatically flashed into the NXT device that was connected to the PC.
				
				
			\end{enumerate}
			
			
	
	\subsubsection{Hardware Setup}	
To reproduce the experiment the following equipments are required :
\begin{enumerate}
    \item
    White A0 Grid Sheet
    \item
    Camera - Microsoft 
    \item
    Assembled robot - Lego NXT 
    \item
    Scales for measuring the length 
    \item
    Vision markers
\end{enumerate}
\vspace{0.5cm}

The general steps to setup the experiment are as following :
\begin{enumerate}
    \item
    Place the White A0 sheet on a flat surface.  Try to remove any bends in the sheet and keep the paper as flat as possible. This will be called the 'map' on which the robot will move on. The measurement system is made of the robot, scale, camera, aruco markers and a paper. 
    \item
    Draw the template drawing of the "floor space" taken by the robot as shown in the figure. Concept of 'Behavior-shaping constraint'\footnote{Behavior shaping constraint : It is a type of design constraint to prevent the user from using the system in a way that it is not intended to be used in. In the case of the template given, the triangle prevents the robot to be placed in the reverse direction.} is used to prevent wrong initial placement of the robot.
    
    
    \begin{figure}[H]
	\centering
    \includegraphics[width=0.6\linewidth ]{Apparatus/map_small.png}
    \caption{ Template of the map}
    \end{figure}    
      
    \begin{figure}[H]
    	\centering
    	\includegraphics[width=0.6\linewidth ]{Apparatus/camera_placement.png}
    	\caption{Top view of the experimental setup without camera}
    \end{figure}
    
    \begin{figure}[H]
    	\centering
    	\includegraphics[width=0.6\linewidth ]{Apparatus/experiment_apparatus_01_small.png}
    	\caption{Top view of the experimental setup}
    \end{figure}
    
    \begin{figure}[H]
     	\centering
     	\includegraphics[width=0.55\linewidth ]{Apparatus/apparatus_front_view.png}
     	\caption{Front view of the experimental setup}
    \end{figure}
    
	\item
	Four aruco markers of different ids are used to find the corners of the grid sheet. The aruco markers are aligned such that the first corner of the marker which is detected by the CV algorithm overlaps with the corner of the sheet.
	\item
	The markers are also aligned to be perfectly parallel to the sheet edges. These markers should be aligned properly since the next preprocessing steps are dependant on this.
	\item
	The camera is placed rigidly such that the whole sheet is visible and the centre of the camera points approximately to the centre of the sheet.	
    \item
    The robot was assembled using the manual given with the LEGO NXT box. The robot firmware was flashed as given in the Software Setup. 
    \item
    We assumed that the driving axle is towards the front(leading edge) of the robot and that the robot origin lies in the centre of the driving axle.
    \item
    The two aruco markers on the robot are placed as ahown in the figure in such a way that one of the markers lies directly on top of the origin of the robot.
    \item
    Place the robot on the A0 sheet over the marked template in such a way that the castor wheel is turned outwards from the robot.
    \item
	The measurands are the coordinates of the robot's markers on the camera.
    
\end{enumerate}
\vspace{0.5cm}

The reference images of the DUT and the proposed marker tracking visualization are given below.

\begin{figure}[h]
	\centering
\includegraphics[width=0.9\linewidth ]{Apparatus/pose.jpeg}
\caption{ Views of the DUT}
\end{figure}

\subsubsection{Camera Calibration}


Calibration in computer vision is the method to find the intrinsic and extrinsic parameters of a particular camera. The intrinsic parameters of a camera deals with the physical qualities of the camera like focal length , skew , distorsion etc. Whereas, the extrinsic parameters of the camera deals with finding the pose of the external world with respect to the camera.\\

The general methods to perform the calibration are as follows.

\begin{enumerate}
	\item
	Download the image of the checkerboard pattern from the link given below.
	\href{https://boofcv.org/images/2/23/Calibration_letter_chessboard_7x5.png}{https://boofcv.org/images/2/23/Calibration\_letter\_chessboard\_7x5.png}
	
	\item
	Take a printout of the pattern on an A4 sheet and mount it on a rigid surface. This will be called as the target.
	
	\item
	Use the camera to be used in the setup to take pictures of the target at different orientation and distances.
	
	\item
	Use the OpenCV code given in the below link to get the calibration parameters for the camera. 
	\href{https://docs.opencv.org/3.4.3/dc/dbb/tutorial_py_calibration.html}{https://docs.opencv.org/3.4.3/dc/dbb/tutorial\_py\_calibration.html}
	
	\item
	The calibration parameters that are found will be used for removing the errors like barrel, radial distorsion and also to find the precise 3D pose of the marker in the image.


\end{enumerate}

\subsection{General Terms Formalization}


	\begin{itemize}
		\item	
		\textbf{Measurand :}
		\begin{itemize}
			\item
			Pose (x-coordinate, y-coordinate, orientation)
		\end{itemize}
		
		\item
		\textbf{Measurement :}
		\begin{itemize}
			\item
			Distance (mm)
			\item
			Angle (degrees)
		\end{itemize}
		\item
		\textbf{Measuring Principle :}
		\begin{itemize}
			\item
			Computer Vision
		\end{itemize} 
		\item
		\textbf{Measurement facility :}
		\begin{itemize}
			\item
			Camera
		\end{itemize} 
		\item
		\textbf{Device Under Test (DUT):}
		\begin{itemize}
			\item
			Lego NXT
		\end{itemize} 
		\item
		\textbf{Measurement System :}
		\begin{itemize}
			\item
			Grid Sheet
			\item
			Markers
			\item
			Camera
		\end{itemize}
		\item
		\textbf{Measuring method: }
		\begin{itemize}
			\item
			Run the robot on the grid sheet as explained in the next section.
			\item
			Capture images using a fixed camera of the entire sheet at the starting position and ending position of the robot.
			\item
			Find the pose of the robot by using the Computer Vision algorithm on the images captured.
		\end{itemize}
\end{itemize}

\subsection{Procedure}
	\subsubsection{Experimental Steps}
	
\begin{enumerate}
	\item
	For this experiment, the camera should be placed rigidly directly above the experiment setup such that the full map is visible in the camera frame. 
	\item
	Before beginning the experiment the camera should be calibrated and the obtained parameters should be used to compensate for the lens distortion and other errors in the image. 
	\item
	Two small markers should be attached on the flat surface of the robot, one on the front and one on top of the origin of the robot. The markers should be visible in the camera frame captured by the overhead camera. (The two markers should have different ID to distinguish between them)
	\item
    Using Computer-vision the two markers on the robot can be tracked and localized. The centre of the markers can be found and be used to calculate the offset from the actual robot origin using a scale or any other measuring device.
	\item
	The robot is programmed to move using the initial pose and the desired final pose.
	\item
	The initial pose and the final pose can be found by CV and position and pose in the required form can be extracted.
	\item
	20 measurements would be performed for each end point of the trajectory. Mean and standard deviation will be computed from the measurement. These measured values would be used to compute the accuracy and precision of the pose variation. 
	
\end{enumerate}
\vspace{0.5cm}

\subsubsection{Computer Vision Algorithm}

\begin{enumerate}
		\item
		Preprocessing the image involves the following steps :
		\vspace{0.2cm}
		\begin{enumerate}
			\item
			Camera calibration is done to find the intrinsic and extrinsic parameters of the camera.	These parameters are then used to remove the radial distortion from the image.
			\item
			The aruco markers on the four corners are then used to perform perspective transformation. This helps in removing minor skews in the image.
			\item
			The four markers on the corners are then used to crop the image.			
		\end{enumerate}
		\vspace{0.3cm}
		\item
		Using the preprocessed image, the algorithm tries to find the two aruco markers that are placed on the robot.
		\item
		Using geometric calculations, the center of the aruco markers on the robots are found. 
		\item
		The marker positions are in pixels since it is directly calculated from the image. A transformation is performed on the pixel coordinates to convert it into 'millimeter' coordinates of the map.
		\item
		The scripts written for the experiment along with the documentation of each of the function are given in the following repository. (\href{https://github.com/njanirudh/SEE-Project}{https://github.com/njanirudh/SEE-Project})
\end{enumerate}

\vspace{0.5cm}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.2\linewidth ]{Extra/marker.png}
	\caption{ Example of Aruco marker used for computer vision}
\end{figure}

\includepdf{Extra/pipeline.png}

\subsection{Observations}

\subsubsection{Problems}

\begin{enumerate}
	\item
	This experiment accuracy and precision depended on the following aspects:
	\begin{enumerate}
		\item
		Camera Setup with respect to the grid sheet
		\item
		Lighting conditions
		\item
		Image recognition algorithms
	\end{enumerate}	 
	\item
	The robot deviated from the expected trajectory towards the left due to the following reasons:
	\begin{enumerate}
		\item
		Uneven weight distributions of the robot
		\item
		Difference in the tractions
		\item
		Faster rotation of one motor compared to the other
	\end{enumerate}
	\item
	Difference in the starting position of the robot during the experiment caused variations in the end pose of the robot.
	\item
	Mechanical adjustments performed on the DUT during the experiment affected the end poses.
	\item
	Pressing the start button of the robot at its start position also caused slight changes in the start pose.
	\item
	Errors that occured due to the markers are given below:
	\begin{enumerate}
		\item
		A major source of error in the case of this experiment is that the compensation for parallax error when considering the markers is not done. This might cause the actual position of the marker corners to be slightly deviated from the result given without the parallax compensation.
		
		\item
		The marker placed at the front of the robot gets hidden at times when the robot moves to the left. This prevents the camera from detecting the marker.
		
		\vspace{0.5cm}
		
		\begin{figure}[h]
			\centering
			\includegraphics[width=0.35\linewidth ]{Extra/hidden_marker.png}
			\caption{ Hidden marker}
		\end{figure}
		
		\item
		The bounding box may not encompass the whole marker. This causes inaccurate calculation of marker centers.
		
		\vspace{0.5cm}
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.35\linewidth ]{Extra/marker_detection_error.png}
			\caption{Bounding Box Error}
		\end{figure}
		
		\item
		The marker in the image appears skewed, which results in inaccurate calculation of pose.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.45\linewidth ]{Extra/skew.png}
			\caption{Skewed Marker}
		\end{figure}
		
		
	\end{enumerate}
	
	
\end{enumerate}


\newpage
\subsubsection{Data Visualisation}

The origin of the original map (grid sheet) that was considered was at the top-left corner. However, the plots that have been displayed in this section have the origin in the bottom-left corner and hence the original images have been mirrored to fit the plot axes.

\begin{enumerate}
	\item
	The scatter plot of the initial pose of the robot has been displayed in the figure below.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth ]{Pose/all.png}
	\caption{Initial Pose}
\end{figure}

\newpage
\item
The scatter plot of the end pose of the robot after it moved forward has been displayed in the figure below.
It can be observed that there is a slight deviation of the robot on one side. This can be attributed to the 
mechanical faults in the robot or uneven weight distribution.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth ]{Pose/straight.png}
	\caption{End Pose - Forward}
\end{figure}



\newpage
\item
The scatter plot of the end pose of the robot after it moved in the left arc has been displayed in the figure below.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth ]{Pose/left.png}
	\caption{End Pose - Left}
\end{figure}


\newpage
\item
The scatter plot of the end pose of the robot after it moved in the right arc has been displayed in the figure below.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth ]{Pose/right.png}
	\caption{End Pose - Right}
\end{figure}



\newpage
\item
The plot of the poses of the robot has been displayed in the figure below.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth ]{Pose/all_wo_bg.png}
	\caption{All Poses}
\end{figure}


\end{enumerate}

\newpage
\section{Task 2 : Statistical Evaluation}

\subsection{Aim}
\Large
The objective of this task is to characterise the observed behaviour from the previous experiment in terms of statistical parameters and estimate the distribution governing the spread of the stop positions.

\subsection{Procedure}

The data obtained from the previous experiment is used to fit to a Gaussian probability distribution by executing an algorithm in Python. The code used for this can be found in the github repository \href{https://github.com/njanirudh/SEE-Project/tree/dev}{https://github.com/njanirudh/SEE-Project/tree/dev}
The general steps for statistical evaluating data are :-
\begin{enumerate}
	\item The extreme outliers in the data are removed by using the Chebyshev's outlier algorithms. 
	\item Perform PCA on the x,y and the angle data for each of the three poses (start,forward,left,right). 
	PCA will help in mean-centering the data while selecting the axis where the projection of the actual data is maximum. 
	\item Chi-squared test is performed on the data to check if the data fits a gaussian distribution or not. 
	Since Chi-squared test requires a minimum of 5 points, the number of bins selected for 20 observations is 4.
	\item Python functions provided in the github repository are used to perform PCA of the data, chi-squared test and also generate the histograms given below.
	
\end{enumerate}
	

\subsection{Observations}
		
Given below are the curves for Gaussian fit from the observed data.

\includepdf{Graphs/start_merged.png}
\includepdf{Graphs/forward_merged.png}
\includepdf{Graphs/left_merged.png}
\includepdf{Graphs/right_merged.png}

The data obtained from the experiments performed can be used to measure the precision.
Since the exact final position of the robot cannot be calculated using the data and the measurements available to us, the accuracy of the data cannot be found.

\begin{table}[ht]				
	\centering
	\begin{tabular}{ | C{3cm} | C{3cm}|  C{3cm} | C{3cm} |} 
		\hline
		\textbf{Parameter} & \textbf{Forward} & \textbf{Right} & \textbf{Left}\\ 
		\hline
		Mean\_X(mm)  & 765.83 & 700.38 & 690.38  \\ 
		\hline
		Mean\_Y(mm)  & 335.11 & 520.14 & 171.27  \\  
		\hline
		Mean\_Theta(deg)  & 14.45 & -24.81 & 40.88  \\ 
		\hline
		Variance\_X(mm)  & $\pm$ 10.56 & $\pm$12.52 & $\pm$15.83 \\  
		\hline
		Variance\_Y(mm)  & $\pm$104.03 & $\pm$104.06 & $\pm$104.61  \\ 
		\hline
		Variance\_Theta(deg)  & $\pm$10.8 & $\pm$0.39 & $\pm$0.91  \\  
		\hline
	\end{tabular}
	\caption{Observed Parameters}
	\label{Tab:Tcr}
\end{table}

\begin{enumerate}
	\item
	The observation in the table shows that the variance along y direction is more than along x direction when the robot moves in arc.
	\item
	The above is attributed to the fact that a small change in the angle
	causes a bigger change in y direction, the further the robot drives.
	Thus also the precision in x direction is better than in y.
	\item
	It can also be seen that the distance in x direction for the right arc
	is bigger than for the left, while the distance in y is bigger for the
	left arc. An explanation for this could be that the right wheel is rotating faster than the left wheel. This is also supported by the fact that the robot moves slightly to the left when programmed to move straight.
\end{enumerate}


\subsection{Conclusion}
An experiment was performed using LEGO NXT robot. 
20 measurement of the pose were taken from a common start position and then after reaching an end position (straight,left,right).
The measurements were plotted on the graph and it was concluded by performing a chi-squared test that the measurements follow a Gaussian distribution.  

\end{document}


